{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNLwsm6rQSybklqA/qezJFj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marlo37/Tensorflow/blob/main/5_Introduction_to_graphs_and_tf_function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ],
      "metadata": {
        "id": "i1GLOww9t2i5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcPpKxKDttOz"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to graphs and `tf.function`"
      ],
      "metadata": {
        "id": "EjlsWmdOt8Ee"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4zzZVZtQb1w"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/intro_to_graphs\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/intro_to_graphs.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/intro_to_graphs.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/guide/intro_to_graphs.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "\n",
        "This guide goes beneath the surface of TensorFlow and Keras to demonstrate how TensorFlow works. If you instead want to immediately get started with Keras, check out the [collection of Keras guides](https://www.tensorflow.org/guide/keras/).\n",
        "\n",
        "In this guide, you'll learn how TensorFlow allows you to make simple changes to your code to get graphs, how graphs are stored and represented, and how you can use them to accelerate your models.\n",
        "\n",
        "Note: For those of you who are only familiar with TensorFlow 1.x, this guide demonstrates a very different view of graphs.\n",
        "\n",
        "**This is a big-picture overview that covers how `tf.function` allows you to switch from eager execution to graph execution.** For a more complete specification of `tf.function`, go to the [Better performance with `tf.function`](./function.ipynb) guide.\n"
      ],
      "metadata": {
        "id": "jXQlFUXouB2h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 가이드는 TensorFlow의 구동 방식을 보여주기 위해 TensorFlow 및 Keras의 표면 아래로 이동합니다. 대신 Keras를 즉시 시작하려면 Keras 가이드 모음을 확인하십시오.\n",
        "\n",
        "이 가이드에서는 TensorFlow를 사용하여 코드를 간단하게 변경하여 `graph`를 얻는 방법, 그래프를 저장하고 표현하는 방법, 그리고 이를 사용하여 모델을 가속화하는 방법을 배웁니다.\n",
        "\n",
        "참고: TensorFlow 1.x에만 익숙한 사용자를 위해 이 가이드는 매우 다른 그래프 보기를 보여줍니다.\n",
        "\n",
        "이것은 `tf.function`을 사용하여 `eager` 실행에서 `graph` 실행으로 전환하는 방법을 다루는 큰 그림 개요입니다. `tf.function`에 대한 보다 완전한 사양을 보려면 `tf.function으로 성능 향상 가이드`로 이동하십시오."
      ],
      "metadata": {
        "id": "avDRcdmQuDqe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What are graphs?\n",
        "\n",
        "In the previous three guides, you ran TensorFlow **eagerly**. <font color=\"red\">This means TensorFlow operations are executed by Python, operation by operation, and returning results back to Python.[**eager mode 정의**]</font>\n",
        "\n",
        "While eager execution has several unique advantages, graph execution enables portability outside Python and tends to offer better performance. **Graph execution** means that tensor computations are executed as a *TensorFlow graph*, sometimes referred to as a `tf.Graph` or simply a \"graph.\"\n",
        "\n",
        "**Graphs are data structures that contain a set of `tf.Operation` objects, which represent units of computation; and `tf.Tensor` objects, which represent the units of data that flow between operations.** They are defined in a `tf.Graph` context. Since these graphs are data structures, they can be saved, run, and restored all without the original Python code.\n",
        "\n",
        "This is what a TensorFlow graph representing a two-layer neural network looks like when visualized in TensorBoard:"
      ],
      "metadata": {
        "id": "qwcYPIcFuFHx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이전 세 가이드에서는 TensorFlow를 `eagerly` 실행했습니다. 즉, TensorFlow 작업은 Python에 의해 실행되고 ops별로 실행되고 결과를 Python으로 다시 반환합니다.[eager mode 정의]\n",
        "\n",
        "`eager` 실행에는 몇 가지 고유한 장점이 있지만 `graph` 실행은 Python 외부에서 이식성을 가능하게 하고 더 나은 성능을 제공하는 경향이 있습니다. `graph` 실행은 텐서 계산이 tf.Graph 또는 단순히 \"그래프\"라고도 하는 TensorFlow `graph`로 실행됨을 의미합니다.\n",
        "\n",
        "`graph`는 계산 단위를 나타내는 tf.Operation 개체 집합을 포함하는 데이터 구조입니다. 작업 간에 흐르는 데이터 단위를 나타내는 tf.Tensor 객체. tf.Graph 컨텍스트에서 정의됩니다. 이 `graph`는 데이터 구조이기 때문에 원본 Python 코드 없이 모두 저장, 실행 및 복원할 수 있습니다.\n",
        "\n",
        "다음은 2계층 신경망을 TensorBoard에서 시각화한 TensorFlow `graph`의 모습입니다."
      ],
      "metadata": {
        "id": "cb5W3B7duHCG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img alt=\"A simple TensorFlow graph\" src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/intro_to_graphs/two-layer-network.png?raw=1\">"
      ],
      "metadata": {
        "id": "itjdvLYGuI2E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The benefits of graphs\n",
        "\n",
        "With a graph, you have a great deal of flexibility.  You can use your TensorFlow graph in environments that don't have a Python interpreter, like mobile applications, embedded devices, and backend servers. TensorFlow uses graphs as the format for [saved models](./saved_model.ipynb) when it exports them from Python.\n",
        "\n",
        "Graphs are also easily optimized, allowing the compiler to do transformations like:\n",
        "\n",
        "* Statically infer the value of tensors by folding constant nodes in your computation *(\"[constant folding](https://en.wikipedia.org/wiki/Constant_folding):컴파일러 최적화\")*.\n",
        "* Separate sub-parts of a computation that are independent and split them between threads or devices.\n",
        "* Simplify arithmetic operations by eliminating common subexpressions.\n"
      ],
      "metadata": {
        "id": "5GFhMTUBuOVI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "그래프를 사용하면 상당한 유연성을 갖게 됩니다. 모바일 애플리케이션, 임베디드 기기, 백엔드 서버와 같이 Python 인터프리터가 없는 환경에서 TensorFlow 그래프를 사용할 수 있습니다. Python에서 TensorFlow를 export할 때 saved model의 형식으로 그래프를 사용합니다.\n",
        "\n",
        "그래프는 또한 쉽게 최적화되어 컴파일러에서 다음과 같은 변환을 수행할 수 있습니다.\n",
        "\n",
        "* 연산에서 상수 노드를 폴딩함으로써 텐서의 값을 정적으로 유추합니다.\n",
        "* 독립적인 연산의 하위 부분을 분리하고 이를 스레드 또는 장치 간에 분할합니다.\n",
        "* 일반적인 하위 표현식을 제거하여 산술 연산을 단순화합니다."
      ],
      "metadata": {
        "id": "EElQC_5suP7h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is an entire optimization system, [Grappler](./graph_optimization.ipynb), to perform this and other speedups.\n",
        "\n",
        "In short, graphs are extremely useful and let your TensorFlow run **fast**, run **in parallel**, and run efficiently **on multiple devices**.\n",
        "\n",
        "However, you still want to define your machine learning models (or other computations) in Python for convenience, and then automatically construct graphs when you need them."
      ],
      "metadata": {
        "id": "NRVSfpGCuRaX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "위 작업들과 다른 속도 향상을 수행하기 위한 전체 최적화 시스템인 `Grappler`가 있습니다.\n",
        "\n",
        "요컨대, 그래프는 매우 유용하며 TensorFlow를 빠르게 실행하고 병렬로 실행하며 여러 장치에서 효율적으로 실행할 수 있습니다.\n",
        "\n",
        "그러나 편의를 위해 Python에서 머신러닝 모델(또는 기타 계산)을 정의한 다음 필요할 때 자동으로 그래프를 구성하려고 합니다."
      ],
      "metadata": {
        "id": "umt7TRKsuSiN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "8XupCGTPuUAj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import some necessary libraries:"
      ],
      "metadata": {
        "id": "fgntDMBRuVRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import timeit\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "PaqkfMHYt_Jo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Taking advantage of graphs\n",
        "\n",
        "You create and run a graph in TensorFlow by using `tf.function`, either as a direct call or as a decorator. `tf.function` takes a regular function as input and returns a `Function`. **A `Function` is a Python callable that builds TensorFlow graphs from the Python function. You use a `Function` in the same way as its Python equivalent.**\n"
      ],
      "metadata": {
        "id": "ez5Cbx14utZE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "직접 호출[`tf.function()`]이나 데코레이터[@tf.function]를 사용하여 TensorFlow에서 그래프를 만들고 실행합니다. `tf.function`은 일반 함수를 입력으로 받아 `Function`를 반환합니다. <font color=\"blue\"><b>`Function`는 Python 함수[<font color=\"red\">데코레이터의 타겟 또는 tf.function 함수의 인자로 전달된</font>]에서 TensorFlow 그래프를 빌드하는 Python `callable`입니다. Python과 동일한 방식으로 `Function`을 사용합니다.</b></font>"
      ],
      "metadata": {
        "id": "_4dpTGvVuu52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a Python function.\n",
        "def a_regular_function(x, y, b):\n",
        "  x = tf.matmul(x, y)\n",
        "  x = x + b\n",
        "  return x\n",
        "\n",
        "# `a_function_that_uses_a_graph` is a TensorFlow `Function`\n",
        "# a_function_that_uses_a_graph는 \"TensorFlow 그래프를 빌드하는 Python callable.\"\n",
        "a_function_that_uses_a_graph = tf.function(a_regular_function)\n",
        "print(\"a_function_that_uses_a_graph is : \", a_function_that_uses_a_graph)\n",
        "\n",
        "# Make some tensors.\n",
        "x1 = tf.constant([[1.0, 2.0]])\n",
        "y1 = tf.constant([[2.0], [3.0]])\n",
        "b1 = tf.constant(4.0)\n",
        "\n",
        "orig_value = a_regular_function(x1, y1, b1).numpy()\n",
        "\n",
        "# Call a `Function` like a Python function.\n",
        "tf_function_value = a_function_that_uses_a_graph(x1, y1, b1).numpy()\n",
        "\n",
        "# assert(orig_value == tf_function_value)\n",
        "print(\"orig_value=\", orig_value)\n",
        "print(\"tf_function_value=\", tf_function_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vACvmTgRuv9J",
        "outputId": "2978c72b-ccb4-4fe5-cdf5-88a7780de3d1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a_function_that_uses_a_graph is :  <tensorflow.python.eager.polymorphic_function.polymorphic_function.Function object at 0x7b210bacfca0>\n",
            "orig_value= [[12.]]\n",
            "tf_function_value= [[12.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On the outside, a `Function` looks like a regular function you write using TensorFlow operations. [Underneath](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/eager/def_function.py), however, it is *very different*. A `Function` **encapsulates several `tf.Graph`s behind one API** (learn more in the _Polymorphism_ section). That is how a `Function` is able to give you the benefits of graph execution, like speed and deployability (refer to _The benefits of graphs_ above)."
      ],
      "metadata": {
        "id": "0CunFyrsux5h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "외부에서 `Function`는 TensorFlow ops을 사용하여 작성하는 일반 함수처럼 보입니다. 그러나 그 아래에는 매우 다릅니다. `Function`는 하나의 API 뒤에 여러 tf.Graphs를 캡슐화합니다(다형성 섹션에서 자세히 알아보기). 이것이 바로 `Function`이 속도 및 배포 가능성과 같은 그래프 실행의 이점을 제공할 수 있는 방법입니다(위 그래프의 이점 참조)."
      ],
      "metadata": {
        "id": "3mFb4sriuzQG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`tf.function` applies to a function *and all other functions it calls*:"
      ],
      "metadata": {
        "id": "TuX1TQJRu0iY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tf.function이 적용된 함수가,</br> 호출하는 다른 모든 함수에도 tf.function이 적용됩니다."
      ],
      "metadata": {
        "id": "eaJOxT33u19n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inner_function(x, y, b):\n",
        "  x = tf.matmul(x, y)\n",
        "  x = x + b\n",
        "  return x\n",
        "\n",
        "# Use the decorator to make `outer_function` a `Function`.\n",
        "@tf.function\n",
        "def outer_function(x):\n",
        "  y = tf.constant([[2.0], [3.0]])\n",
        "  b = tf.constant(4.0)\n",
        "\n",
        "  return inner_function(x, y, b)"
      ],
      "metadata": {
        "id": "jXY6fX1ku2_f"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note that the callable will create a graph that\n",
        "# includes `inner_function` as well as `outer_function`.\n",
        "outer_function(tf.constant([[1.0, 2.0]])).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6vOKp8cu4kz",
        "outputId": "934ce0af-8e27-4cf6-dec0-65d9c07c280a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you have used TensorFlow 1.x, you will notice that at no time did you need to define a `Placeholder` or `tf.Session`."
      ],
      "metadata": {
        "id": "MPzxDbobu6Sc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "software version\n",
        "Major.Minor.Micro"
      ],
      "metadata": {
        "id": "Tl7b6ttYu7hF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Converting Python functions to graphs\n",
        "\n",
        "Any function you write with TensorFlow will contain a mixture of built-in TF operations and Python logic, such as `if-then` clauses, loops, `break`, `return`, `continue`, and more. While TensorFlow operations are easily captured by a `tf.Graph`, Python-specific logic needs to undergo an extra step in order to become part of the graph. `tf.function` uses a library called AutoGraph (`tf.autograph`) to convert Python code into graph-generating code.\n"
      ],
      "metadata": {
        "id": "fNMn-8VPu82R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorFlow로 작성하는 모든 함수에는 if-then 절, loop, `break`, `return`, `continue` 등과 같은 Python 로직과 내장 TF ops와  혼합되어 있습니다. TensorFlow ops은 tf.Graph로 쉽게 캡처되지만 Python 관련 로직은 그래프의 일부가 되려면 추가 단계를 거쳐야 합니다. `tf.function`은 `AutoGraph(tf.autograph)`라는 라이브러리를 사용하여 Python 코드를 graph-generating code로 변환합니다."
      ],
      "metadata": {
        "id": "phTKIdVPu-TW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_relu(x):\n",
        "  if tf.greater(x, 0):\n",
        "    return x\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "# `tf_simple_relu` is a TensorFlow `Function` that wraps `simple_relu`.\n",
        "tf_simple_relu = tf.function(simple_relu)"
      ],
      "metadata": {
        "id": "5UxhSAEou_30"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"First branch, with graph:\", tf_simple_relu(tf.constant(1)).numpy())\n",
        "print(\"Second branch, with graph:\", tf_simple_relu(tf.constant(-1)).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pk1yVZGqvBOw",
        "outputId": "e5b3a656-cc41-4e61-99cc-a1ec6e78fb09"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First branch, with graph: 1\n",
            "Second branch, with graph: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Though it is unlikely that you will need to view graphs directly, you can inspect the outputs to check the exact results. These are not easy to read, so no need to look too carefully!"
      ],
      "metadata": {
        "id": "UkdT3Gv7vCrV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "그래프를 직접 볼 필요는 없지만 출력을 검사하여 정확한 결과를 확인할 수 있습니다. 이것들은 읽기 쉽지 않으므로 너무 주의 깊게 볼 필요는 없습니다!"
      ],
      "metadata": {
        "id": "0eo2lghBvD26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the graph-generating output of AutoGraph.\n",
        "print(tf.autograph.to_code(simple_relu))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUywMip-vFC1",
        "outputId": "b279cef8-e220-461c-bfbc-f98a5b603c74"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def tf__simple_relu(x):\n",
            "    with ag__.FunctionScope('simple_relu', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
            "        do_return = False\n",
            "        retval_ = ag__.UndefinedReturnValue()\n",
            "\n",
            "        def get_state():\n",
            "            return (do_return, retval_)\n",
            "\n",
            "        def set_state(vars_):\n",
            "            nonlocal retval_, do_return\n",
            "            (do_return, retval_) = vars_\n",
            "\n",
            "        def if_body():\n",
            "            nonlocal retval_, do_return\n",
            "            try:\n",
            "                do_return = True\n",
            "                retval_ = ag__.ld(x)\n",
            "            except:\n",
            "                do_return = False\n",
            "                raise\n",
            "\n",
            "        def else_body():\n",
            "            nonlocal retval_, do_return\n",
            "            try:\n",
            "                do_return = True\n",
            "                retval_ = 0\n",
            "            except:\n",
            "                do_return = False\n",
            "                raise\n",
            "        ag__.if_stmt(ag__.converted_call(ag__.ld(tf).greater, (ag__.ld(x), 0), None, fscope), if_body, else_body, get_state, set_state, ('do_return', 'retval_'), 2)\n",
            "        return fscope.ret(retval_, do_return)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the graph itself.\n",
        "print(tf_simple_relu.get_concrete_function(tf.constant(1)).graph.as_graph_def())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ker2qOdLvHE9",
        "outputId": "4da16dee-e7d6-407c-dc25-ae3ab2ac1f05"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "node {\n",
            "  name: \"x\"\n",
            "  op: \"Placeholder\"\n",
            "  attr {\n",
            "    key: \"_user_specified_name\"\n",
            "    value {\n",
            "      s: \"x\"\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"dtype\"\n",
            "    value {\n",
            "      type: DT_INT32\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"shape\"\n",
            "    value {\n",
            "      shape {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "node {\n",
            "  name: \"Greater/y\"\n",
            "  op: \"Const\"\n",
            "  attr {\n",
            "    key: \"dtype\"\n",
            "    value {\n",
            "      type: DT_INT32\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"value\"\n",
            "    value {\n",
            "      tensor {\n",
            "        dtype: DT_INT32\n",
            "        tensor_shape {\n",
            "        }\n",
            "        int_val: 0\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "node {\n",
            "  name: \"Greater\"\n",
            "  op: \"Greater\"\n",
            "  input: \"x\"\n",
            "  input: \"Greater/y\"\n",
            "  attr {\n",
            "    key: \"T\"\n",
            "    value {\n",
            "      type: DT_INT32\n",
            "    }\n",
            "  }\n",
            "}\n",
            "node {\n",
            "  name: \"cond\"\n",
            "  op: \"StatelessIf\"\n",
            "  input: \"Greater\"\n",
            "  input: \"x\"\n",
            "  attr {\n",
            "    key: \"Tcond\"\n",
            "    value {\n",
            "      type: DT_BOOL\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"Tin\"\n",
            "    value {\n",
            "      list {\n",
            "        type: DT_INT32\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"Tout\"\n",
            "    value {\n",
            "      list {\n",
            "        type: DT_BOOL\n",
            "        type: DT_INT32\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"_lower_using_switch_merge\"\n",
            "    value {\n",
            "      b: true\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"_read_only_resource_inputs\"\n",
            "    value {\n",
            "      list {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"else_branch\"\n",
            "    value {\n",
            "      func {\n",
            "        name: \"cond_false_31\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"output_shapes\"\n",
            "    value {\n",
            "      list {\n",
            "        shape {\n",
            "        }\n",
            "        shape {\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"then_branch\"\n",
            "    value {\n",
            "      func {\n",
            "        name: \"cond_true_30\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "node {\n",
            "  name: \"cond/Identity\"\n",
            "  op: \"Identity\"\n",
            "  input: \"cond\"\n",
            "  attr {\n",
            "    key: \"T\"\n",
            "    value {\n",
            "      type: DT_BOOL\n",
            "    }\n",
            "  }\n",
            "}\n",
            "node {\n",
            "  name: \"cond/Identity_1\"\n",
            "  op: \"Identity\"\n",
            "  input: \"cond:1\"\n",
            "  attr {\n",
            "    key: \"T\"\n",
            "    value {\n",
            "      type: DT_INT32\n",
            "    }\n",
            "  }\n",
            "}\n",
            "node {\n",
            "  name: \"Identity\"\n",
            "  op: \"Identity\"\n",
            "  input: \"cond/Identity_1\"\n",
            "  attr {\n",
            "    key: \"T\"\n",
            "    value {\n",
            "      type: DT_INT32\n",
            "    }\n",
            "  }\n",
            "}\n",
            "library {\n",
            "  function {\n",
            "    signature {\n",
            "      name: \"cond_false_31\"\n",
            "      input_arg {\n",
            "        name: \"cond_placeholder\"\n",
            "        type: DT_INT32\n",
            "      }\n",
            "      output_arg {\n",
            "        name: \"cond_identity\"\n",
            "        type: DT_BOOL\n",
            "      }\n",
            "      output_arg {\n",
            "        name: \"cond_identity_1\"\n",
            "        type: DT_INT32\n",
            "      }\n",
            "    }\n",
            "    node_def {\n",
            "      name: \"cond/Const\"\n",
            "      op: \"Const\"\n",
            "      attr {\n",
            "        key: \"dtype\"\n",
            "        value {\n",
            "          type: DT_BOOL\n",
            "        }\n",
            "      }\n",
            "      attr {\n",
            "        key: \"value\"\n",
            "        value {\n",
            "          tensor {\n",
            "            dtype: DT_BOOL\n",
            "            tensor_shape {\n",
            "            }\n",
            "            bool_val: true\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    node_def {\n",
            "      name: \"cond/Const_1\"\n",
            "      op: \"Const\"\n",
            "      attr {\n",
            "        key: \"dtype\"\n",
            "        value {\n",
            "          type: DT_BOOL\n",
            "        }\n",
            "      }\n",
            "      attr {\n",
            "        key: \"value\"\n",
            "        value {\n",
            "          tensor {\n",
            "            dtype: DT_BOOL\n",
            "            tensor_shape {\n",
            "            }\n",
            "            bool_val: true\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    node_def {\n",
            "      name: \"cond/Const_2\"\n",
            "      op: \"Const\"\n",
            "      attr {\n",
            "        key: \"dtype\"\n",
            "        value {\n",
            "          type: DT_INT32\n",
            "        }\n",
            "      }\n",
            "      attr {\n",
            "        key: \"value\"\n",
            "        value {\n",
            "          tensor {\n",
            "            dtype: DT_INT32\n",
            "            tensor_shape {\n",
            "            }\n",
            "            int_val: 0\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    node_def {\n",
            "      name: \"cond/Const_3\"\n",
            "      op: \"Const\"\n",
            "      attr {\n",
            "        key: \"dtype\"\n",
            "        value {\n",
            "          type: DT_BOOL\n",
            "        }\n",
            "      }\n",
            "      attr {\n",
            "        key: \"value\"\n",
            "        value {\n",
            "          tensor {\n",
            "            dtype: DT_BOOL\n",
            "            tensor_shape {\n",
            "            }\n",
            "            bool_val: true\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    node_def {\n",
            "      name: \"cond/Identity\"\n",
            "      op: \"Identity\"\n",
            "      input: \"cond/Const_3:output:0\"\n",
            "      attr {\n",
            "        key: \"T\"\n",
            "        value {\n",
            "          type: DT_BOOL\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    node_def {\n",
            "      name: \"cond/Const_4\"\n",
            "      op: \"Const\"\n",
            "      attr {\n",
            "        key: \"dtype\"\n",
            "        value {\n",
            "          type: DT_INT32\n",
            "        }\n",
            "      }\n",
            "      attr {\n",
            "        key: \"value\"\n",
            "        value {\n",
            "          tensor {\n",
            "            dtype: DT_INT32\n",
            "            tensor_shape {\n",
            "            }\n",
            "            int_val: 0\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    node_def {\n",
            "      name: \"cond/Identity_1\"\n",
            "      op: \"Identity\"\n",
            "      input: \"cond/Const_4:output:0\"\n",
            "      attr {\n",
            "        key: \"T\"\n",
            "        value {\n",
            "          type: DT_INT32\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    ret {\n",
            "      key: \"cond_identity\"\n",
            "      value: \"cond/Identity:output:0\"\n",
            "    }\n",
            "    ret {\n",
            "      key: \"cond_identity_1\"\n",
            "      value: \"cond/Identity_1:output:0\"\n",
            "    }\n",
            "    attr {\n",
            "      key: \"_construction_context\"\n",
            "      value {\n",
            "        s: \"kEagerRuntime\"\n",
            "      }\n",
            "    }\n",
            "    arg_attr {\n",
            "      key: 0\n",
            "      value {\n",
            "        attr {\n",
            "          key: \"_output_shapes\"\n",
            "          value {\n",
            "            list {\n",
            "              shape {\n",
            "              }\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  function {\n",
            "    signature {\n",
            "      name: \"cond_true_30\"\n",
            "      input_arg {\n",
            "        name: \"cond_identity_1_x\"\n",
            "        type: DT_INT32\n",
            "      }\n",
            "      output_arg {\n",
            "        name: \"cond_identity\"\n",
            "        type: DT_BOOL\n",
            "      }\n",
            "      output_arg {\n",
            "        name: \"cond_identity_1\"\n",
            "        type: DT_INT32\n",
            "      }\n",
            "    }\n",
            "    node_def {\n",
            "      name: \"cond/Const\"\n",
            "      op: \"Const\"\n",
            "      attr {\n",
            "        key: \"dtype\"\n",
            "        value {\n",
            "          type: DT_BOOL\n",
            "        }\n",
            "      }\n",
            "      attr {\n",
            "        key: \"value\"\n",
            "        value {\n",
            "          tensor {\n",
            "            dtype: DT_BOOL\n",
            "            tensor_shape {\n",
            "            }\n",
            "            bool_val: true\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    node_def {\n",
            "      name: \"cond/Identity\"\n",
            "      op: \"Identity\"\n",
            "      input: \"cond/Const:output:0\"\n",
            "      attr {\n",
            "        key: \"T\"\n",
            "        value {\n",
            "          type: DT_BOOL\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    node_def {\n",
            "      name: \"cond/Identity_1\"\n",
            "      op: \"Identity\"\n",
            "      input: \"cond_identity_1_x\"\n",
            "      attr {\n",
            "        key: \"T\"\n",
            "        value {\n",
            "          type: DT_INT32\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    ret {\n",
            "      key: \"cond_identity\"\n",
            "      value: \"cond/Identity:output:0\"\n",
            "    }\n",
            "    ret {\n",
            "      key: \"cond_identity_1\"\n",
            "      value: \"cond/Identity_1:output:0\"\n",
            "    }\n",
            "    attr {\n",
            "      key: \"_construction_context\"\n",
            "      value {\n",
            "        s: \"kEagerRuntime\"\n",
            "      }\n",
            "    }\n",
            "    arg_attr {\n",
            "      key: 0\n",
            "      value {\n",
            "        attr {\n",
            "          key: \"_output_shapes\"\n",
            "          value {\n",
            "            list {\n",
            "              shape {\n",
            "              }\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        attr {\n",
            "          key: \"_user_specified_name\"\n",
            "          value {\n",
            "            s: \"x\"\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "versions {\n",
            "  producer: 1645\n",
            "  min_consumer: 12\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most of the time, `tf.function` will work without  special considerations. However, there are some caveats, and the [`tf.function` guide](./function.ipynb) can help here, as well as the [complete AutoGraph reference](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/index.md)."
      ],
      "metadata": {
        "id": "QWdec_g3vJL7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "대부분의 경우 tf.function은 특별한 고려 없이 작동합니다. 그러나 몇 가지 주의 사항이 있으며 tf.function 가이드와 완전한 AutoGraph 참조가 여기에 도움이 될 수 있습니다."
      ],
      "metadata": {
        "id": "kNYgJYV6vKpm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Polymorphism: one `Function`, many graphs\n",
        "\n",
        "A `tf.Graph` is specialized to a specific type of inputs (for example, tensors with a specific [`dtype`](https://www.tensorflow.org/api_docs/python/tf/dtypes/DType) or objects with the same [`id()`](https://docs.python.org/3/library/functions.html#id])).\n",
        "\n",
        "Each time you invoke a `Function` with a set of arguments that can't be handled by any of its existing graphs (such as arguments with new `dtypes` or incompatible shapes), `Function` creates a new `tf.Graph` specialized to those new arguments. The type specification of a `tf.Graph`'s inputs is known as its **input signature** or just a **signature**. For more information regarding when a new `tf.Graph` is generated and how that can be controlled, go to the _Rules of tracing_ section of the [Better performance with `tf.function`](./function.ipynb) guide.\n",
        "\n",
        "The `Function` stores the `tf.Graph` corresponding to that signature in a `ConcreteFunction`. **A `ConcreteFunction` is a wrapper around a `tf.Graph`.**\n"
      ],
      "metadata": {
        "id": "cUmo6n3GvMGA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tf.Graph는 특정 유형의 입력에 특화되어 있습니다(예: 특정 dtype을 가진 텐서 또는 동일한 id()를 가진 객체).\n",
        "\n",
        "기존 그래프에서 처리할 수 없는 인수 집합(예: 새로운 dtypes 또는 호환되지 않는 shape이 있는 인수)으로 함수를 호출할 때마다 함수는 해당 새로운 인수에 특화된 새로운 tf.Graph를 만듭니다."
      ],
      "metadata": {
        "id": "B4l4sSRgvNk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_relu_p(x):\n",
        "  # print(\"called my_relu\")\n",
        "  return tf.maximum(0., x)"
      ],
      "metadata": {
        "id": "Q_NeBi-pvOvT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(my_relu_p)) # python에서 함수는 function 클래스임!!!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ws783r4fvQKp",
        "outputId": "00f96179-5e4c-436a-8770-6d014312a618"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'function'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def my_relu(x):\n",
        "  print(\"called my_relu\")\n",
        "  return tf.maximum(0., x)"
      ],
      "metadata": {
        "id": "Qce5EFD9vRpe"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(my_relu)) # tensorflow.python.eager.def_function.Function 클래스임!!!"
      ],
      "metadata": {
        "id": "87f8ugfrvTX2",
        "outputId": "8bc6ca63-df59-40b5-f028-e3f5b27cb4d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'tensorflow.python.eager.polymorphic_function.polymorphic_function.Function'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://android.googlesource.com/platform/external/tensorflow/+/632ff3f6169ef18a6947c53bd6f3cb5bf7fc26a6/tensorflow/python/eager/def_function.py"
      ],
      "metadata": {
        "id": "jfJJYiVdCPRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# `my_relu` creates new graphs as it observes more signatures.\n",
        "\n",
        "print(my_relu(tf.constant(5.5)))  # argument는\n",
        "                                  # 스칼라인 Tensor, 시그너쳐"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9khfdkVcCQdO",
        "outputId": "d5d594d0-89ae-4cb6-e7b7-3bea03d547ad"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "called my_relu\n",
            "tf.Tensor(5.5, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "그래프 Function의 signature가 Tensor가 아니라면,\n",
        "즉, 파이썬 데이터 타입이라면, 새로운 시그너쳐가 계속 만들어진다."
      ],
      "metadata": {
        "id": "ssVr64FVCS2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(my_relu([1, -1])) # argument는,\n",
        "                        # element가 정수인 파이썬 list, 시그너쳐"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aHde-AxCUKs",
        "outputId": "53caaf3e-a2cb-440a-84c3-3b2321313c4e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "called my_relu\n",
            "tf.Tensor([1. 0.], shape=(2,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(my_relu([3, -7])) # argument는,\n",
        "#                         # element가 정수인 list, 시그너쳐"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swwElaWuCWcJ",
        "outputId": "c6bb4bc2-9aee-43a1-f60a-99b1df025e48"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "called my_relu\n",
            "tf.Tensor([3. 0.], shape=(2,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the `Function` has already been called with that signature, `Function` does not create a new `tf.Graph`."
      ],
      "metadata": {
        "id": "5LIn2o-ECZ27"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "함수가 이미 해당 signature으로 호출된 경우 함수는 새로운 tf.Graph를 생성하지 않습니다."
      ],
      "metadata": {
        "id": "sHGgHxclCbfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# These two calls do *not* create new graphs.\n",
        "print(my_relu(tf.constant(-2.5))) # Signature matches `tf.constant(5.5)`.\n",
        "print(my_relu(tf.constant([-1., 1.]))) # Signature matches `tf.constant([3., -3.])`."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9EycnlyCc68",
        "outputId": "98824456-e606-4b04-efb1-b48d51beb378"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0.0, shape=(), dtype=float32)\n",
            "called my_relu\n",
            "tf.Tensor([0. 1.], shape=(2,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because it's backed by multiple graphs, a `Function` is **polymorphic**. That enables it to support more input types than a single `tf.Graph` could represent, and to optimize each `tf.Graph` for better performance."
      ],
      "metadata": {
        "id": "VjTGhvn_CeOe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "여러개의 그래프가 지원되기 때문에 `Function`는 다형성입니다. 이를 통해 단일 tf.Graph가 표현할 수 있는 것보다 더 많은 입력 유형[signature]을 지원하고 더 나은 성능을 위해 각 tf.Graph를 최적화할 수 있습니다."
      ],
      "metadata": {
        "id": "YYEFiGL0Cfd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# There are three `ConcreteFunction`s (one for each graph) in `my_relu`.\n",
        "# The `ConcreteFunction` also knows the return type and shape!\n",
        "print(my_relu.pretty_printed_concrete_signatures())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxzYT4RXCgYe",
        "outputId": "f75cad35-7d27-47aa-a646-18ccae444e3b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Parameters:\n",
            "  x (POSITIONAL_OR_KEYWORD): TensorSpec(shape=(), dtype=tf.float32, name=None)\n",
            "Output Type:\n",
            "  TensorSpec(shape=(), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  None\n",
            "\n",
            "Input Parameters:\n",
            "  x (POSITIONAL_OR_KEYWORD): List[Literal[1], Literal[-1]]\n",
            "Output Type:\n",
            "  TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  None\n",
            "\n",
            "Input Parameters:\n",
            "  x (POSITIONAL_OR_KEYWORD): List[Literal[3], Literal[-7]]\n",
            "Output Type:\n",
            "  TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  None\n",
            "\n",
            "Input Parameters:\n",
            "  x (POSITIONAL_OR_KEYWORD): TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
            "Output Type:\n",
            "  TensorSpec(shape=(2,), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using `tf.function`\n",
        "\n",
        "So far, you've learned how to convert a Python function into a graph simply by using `tf.function` as a decorator or wrapper. But in practice, getting `tf.function` to work correctly can be tricky! In the following sections, you'll learn how you can make your code work as expected with `tf.function`."
      ],
      "metadata": {
        "id": "7nqGVrDGCqFi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "지금까지 `tf.function`을 데코레이터 또는 래퍼로 사용하여 Python 함수를 그래프로 변환하는 방법을 배웠습니다. 그러나 실제로는 `tf.function`이 올바르게 작동하도록 하는 것이 까다로울 수 있습니다! 다음 섹션에서는 `tf.function`을 사용하여 코드가 예상대로 작동하도록 하는 방법을 배웁니다."
      ],
      "metadata": {
        "id": "Z0h_ppCWCu4S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Graph execution vs. eager execution\n",
        "\n",
        "The code in a `Function` can be executed both eagerly and as a graph. By default, `Function` executes its code as a graph:\n"
      ],
      "metadata": {
        "id": "AJFKMpwyCw4x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Function`의 코드는 `eagerly` 실행될 수도 있고 `graph`로 실행될 수도 있습니다. 기본적으로 `Function`은 코드를 그래프로 실행합니다."
      ],
      "metadata": {
        "id": "-lYK3MIxCy3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def get_MSE(y_true, y_pred):\n",
        "  # print(\"called get_MSE\")\n",
        "  sq_diff = tf.pow(y_true - y_pred, 2)\n",
        "  return tf.reduce_mean(sq_diff)"
      ],
      "metadata": {
        "id": "Ez7l2j8DC0Dq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = tf.random.uniform([5], maxval=10, dtype=tf.int32)\n",
        "y_pred = tf.random.uniform([5], maxval=10, dtype=tf.int32)\n",
        "print(y_true)\n",
        "print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vraD7UFcCnD6",
        "outputId": "74d0e46f-9018-4b12-ccb6-a1e936bea763"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([4 5 8 3 6], shape=(5,), dtype=int32)\n",
            "tf.Tensor([0 1 6 8 4], shape=(5,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_MSE(y_true, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNAX-7xAC3Pc",
        "outputId": "f4e976e3-75a8-4a25-d755-0ce94ff4951e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=13>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To verify that your `Function`'s graph is doing the same computation as its equivalent Python function, you can make it execute eagerly with `tf.config.run_functions_eagerly(True)`. This is a switch that **turns off `Function`'s ability to create and run graphs**, instead of executing the code normally."
      ],
      "metadata": {
        "id": "FZyit-EyDHdh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Function`의 그래프가 원래의 Python 함수와 동일한 계산을 수행하는지 확인하려면 `tf.config.run_functions_eagerly(True)`를 사용하여 빠르게 실행되도록 할 수 있습니다. 이것은 코드를 정상적으로 실행하는 대신 `graph`를 생성하고 실행하는 `Function`의 기능을 끄는 스위치입니다."
      ],
      "metadata": {
        "id": "dbXIg2cYDIz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.run_functions_eagerly(True)"
      ],
      "metadata": {
        "id": "qQrgaZelDJ17"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_MSE(y_true, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roU-w-8YDLPv",
        "outputId": "f86fd109-da01-4fed-8b66-f340a0d14965"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=13>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Don't forget to set it back when you are done.\n",
        "tf.config.run_functions_eagerly(False)"
      ],
      "metadata": {
        "id": "J0R6EFh3DMnV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, `Function` can behave differently under graph and eager execution. The Python [`print`](https://docs.python.org/3/library/functions.html#print) function is one example of how these two modes differ. Let's check out what happens when you insert a `print` statement to your function and call it repeatedly."
      ],
      "metadata": {
        "id": "FVeN2L5pDOIa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "그러나 `Function`은 `graph`와 `eager` 실행에서 다르게 동작할 수 있습니다. Python의 print함수는 이 두 모드가 어떻게 다른지 보여주는 한 가지 예입니다. 함수에 print 문을 삽입하고 반복적으로 호출하면 어떻게 되는지 확인해 봅시다."
      ],
      "metadata": {
        "id": "h4MaPpiaDP25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def get_MSE(y_true, y_pred):\n",
        "  # print(\"Calculating MSE!\") ##############\n",
        "  tf.print(\"Calculating MSE!\")\n",
        "  sq_diff = tf.pow(y_true - y_pred, 2)\n",
        "  return tf.reduce_mean(sq_diff)"
      ],
      "metadata": {
        "id": "AeQFQlZeDQ7R"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observe what is printed:"
      ],
      "metadata": {
        "id": "72h8JDxCDSVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "error = get_MSE(y_true, y_pred)\n",
        "error = get_MSE(y_true, y_pred)\n",
        "error = get_MSE(y_true, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrAitpHQDTnM",
        "outputId": "15471e42-982d-4fd6-93ea-3ac7b20151e1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating MSE!\n",
            "Calculating MSE!\n",
            "Calculating MSE!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Is the output surprising? **`get_MSE` only printed once even though it was called *three* times.**\n",
        "\n",
        "To explain, the `print` statement is executed when `Function` runs the original code in order to create the graph in a process known as \"tracing\" (refer to the _Tracing_ section of the [`tf.function` guide](./function.ipynb). **Tracing captures the TensorFlow operations into a graph, and `print` is not captured in the graph.**  That graph is then executed for all three calls **without ever running the Python code again**.\n",
        "\n",
        "As a sanity check, let's turn off graph execution to compare:"
      ],
      "metadata": {
        "id": "sD6Esj_HDVS2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "출력이 놀랍습니까? get_MSE는 세 번 호출되었지만 한 번만 print함수의 스트링이 콘솔에 출력 되었습니다.\n",
        "\n",
        "설명하자면, print 문은 \"tracing\"으로 알려진 프로세스에서 그래프를 생성하기 위해 `Function`이 원본 코드를 실행할 때 실행됩니다(tf.function 가이드의 Tracing 섹션 참조). Tracing은 TensorFlow ops을 그래프로 캡처하고, 그리고 print함수는 그래프에 캡처되지 않습니다. 그런 다음 해당 그래프는 Python 코드를 다시 실행하지 않고 세 호출 모두에 대해 실행됩니다.\n",
        "\n",
        "온전한 확인을 위해 그래프 실행을 꺼서 비교하겠습니다."
      ],
      "metadata": {
        "id": "7tYyOt25DWtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, globally set everything to run eagerly to force eager execution.\n",
        "tf.config.run_functions_eagerly(True)"
      ],
      "metadata": {
        "id": "7RCTON2fDX6k"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Observe what is printed below.\n",
        "error = get_MSE(y_true, y_pred)\n",
        "error = get_MSE(y_true, y_pred)\n",
        "error = get_MSE(y_true, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-ekPZpnDbVh",
        "outputId": "c79297e2-2366-406a-9590-ddaee4516a2b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating MSE!\n",
            "Calculating MSE!\n",
            "Calculating MSE!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "eager 모드에서 실행된 것은 get_MSE의 Function인가???"
      ],
      "metadata": {
        "id": "B2z7TaM_DddV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(get_MSE))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AR9pqi4QDeoF",
        "outputId": "a7f24cf9-de21-4b32-9331-bcf88af94d89"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'tensorflow.python.eager.polymorphic_function.polymorphic_function.Function'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.run_functions_eagerly(False)"
      ],
      "metadata": {
        "id": "2UsMHmbrDf_a"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`print` is a *Python side effect*, and there are other differences that you should be aware of when converting a function into a `Function`. Learn more in the _Limitations_ section of the [Better performance with `tf.function`](./function.ipynb) guide."
      ],
      "metadata": {
        "id": "KDg3_LtMDihQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`print`는 파이썬의 부작용이며, 파이썬 함수를 `Function`로 변환할 때 알아야 할 다른 차이점이 있습니다. tf.function으로 성능 향상 가이드의 제한 사항 섹션에서 자세히 알아보세요."
      ],
      "metadata": {
        "id": "D9jRyARHDj6l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: If you would like to print values in both eager and graph execution, use `tf.print` instead."
      ],
      "metadata": {
        "id": "SzXMbudDDlSL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Non-strict execution\n",
        "\n",
        "<a id=\"non-strict\"></a>\n",
        "\n",
        "Graph execution only executes the operations necessary to produce the observable effects, which includes:\n",
        "\n",
        "- The return value of the function\n",
        "- Documented well-known side-effects such as:\n",
        "  - Input/output operations, like `tf.print`\n",
        "  - Debugging operations, such as the assert functions in `tf.debugging`\n",
        "  - Mutations of `tf.Variable`\n",
        "\n",
        "This behavior is usually known as \"Non-strict execution\", and differs from eager execution, which steps through all of the program operations, needed or not.\n",
        "\n",
        "In particular, runtime error checking does not count as an observable effect. If an operation is skipped because it is unnecessary, it cannot raise any runtime errors.\n",
        "\n",
        "In the following example, the \"unnecessary\" operation `tf.gather` is skipped during graph execution, so the runtime error `InvalidArgumentError` is not raised as it would be in eager execution. Do not rely on an error being raised while executing a graph."
      ],
      "metadata": {
        "id": "s18JAFAXDmvs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "그래프 실행은 다음을 포함하여 관찰 가능한 효과를 생성하는 데 필요한 ops만 실행합니다.\n",
        "\n",
        "* 함수의 반환 값\n",
        "* 다음과 같은 문서화된 잘 알려진 부작용:\n",
        "  \n",
        "  1. tf.print와 같은 input/output ops\n",
        "  2. tf.debugging의 assert 기능과 같은 디버깅 작업\n",
        "  3. tf.Variable의 Mutations"
      ],
      "metadata": {
        "id": "8-Eks-vCDocQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"red\">이것은 일반적으로 \"비엄격 실행\"으로 알려져 있으며, 필요하거나 필요하지 않은 모든 프로그램 ops을 단계별로 실행하는 `eager` 실행과 다릅니다.\n",
        "\n",
        "특히 런타임 오류 검사는 관찰 가능한 효과로 계산되지 않습니다. 만약 특정 op가 불필요해서 스킵된다면, 런타임 오류가 발생할 수 없습니다.\n",
        "\n",
        "다음 예에서는 그래프 실행 중에 \"불필요한\" op인 tf.gather를 스킵함으로써 `eager` 실행에서와 같이 런타임 오류 InvalidArgumentError가 발생하지 않습니다. 그래프를 실행하는 동안 발생하는 오류에 의존하지 마십시오.</font>"
      ],
      "metadata": {
        "id": "PYq2No3hDpqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unused_return_eager(x):\n",
        "  # Get index 1 will fail when `len(x) == 1`\n",
        "  tf.gather(x, [1]) # unused\n",
        "  return x"
      ],
      "metadata": {
        "id": "qIcIBczyDrHC"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  print(unused_return_eager(tf.constant([0.0])))\n",
        "except tf.errors.InvalidArgumentError as e:\n",
        "  # All operations are run during eager execution so an error is raised.\n",
        "  print(f'{type(e).__name__}: {e}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhTLhmLvDsiG",
        "outputId": "831d1dd0-55a0-4d6d-95d4-aa71bf496c57"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0.], shape=(1,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def unused_return_graph(x):\n",
        "  # runtime error checking does not count as an observable effect.\n",
        "  tf.gather(x, [1]) # unused\n",
        "  # tf.gather(x, [0])\n",
        "  return x"
      ],
      "metadata": {
        "id": "XdY_L3ugDtx6"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.autograph.to_code(unused_return_eager))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7rmPZvDDvFB",
        "outputId": "770a8342-9f3e-45c3-e7af-a886da645941"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def tf__unused_return_eager(x):\n",
            "    with ag__.FunctionScope('unused_return_eager', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
            "        do_return = False\n",
            "        retval_ = ag__.UndefinedReturnValue()\n",
            "        ag__.converted_call(ag__.ld(tf).gather, (ag__.ld(x), [1]), None, fscope)\n",
            "        try:\n",
            "            do_return = True\n",
            "            retval_ = ag__.ld(x)\n",
            "        except:\n",
            "            do_return = False\n",
            "            raise\n",
            "        return fscope.ret(retval_, do_return)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Only needed operations are run during graph execution. The error is not raised.\n",
        "print(unused_return_graph(tf.constant([0.0])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiu1uAX4Dy8u",
        "outputId": "016550bd-25c7-4453-e577-c23ae922fad8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0.], shape=(1,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `tf.function` best practices\n",
        "\n",
        "It may take some time to get used to the behavior of `Function`.  To get started quickly, first-time users should play around with decorating toy functions with `@tf.function` to get experience with going from eager to graph execution.\n",
        "\n",
        "*Designing for `tf.function`* may be your best bet for writing graph-compatible TensorFlow programs. Here are some tips:\n",
        "-  Toggle between eager and graph execution early and often with `tf.config.run_functions_eagerly` to pinpoint if/ when the two modes diverge.\n",
        "- Create `tf.Variable`s\n",
        "outside the Python function and modify them on the inside. The same goes for objects that use `tf.Variable`, like `tf.keras.layers`, `tf.keras.Model`s and `tf.keras.optimizers`.\n",
        "- Avoid writing functions that depend on outer Python variables, excluding `tf.Variable`s and Keras objects. Learn more in _Depending on Python global and free variables_ of the [`tf.function` guide](./function.ipynb).\n",
        "- Prefer to write functions which take tensors and other TensorFlow types as input. You can pass in other object types but be careful! Learn more in _Depending on Python objects_ of the [`tf.function` guide](./function.ipynb).\n",
        "- Include as much computation as possible under a `tf.function` to maximize the performance gain. For example, decorate a whole training step or the entire training loop.\n"
      ],
      "metadata": {
        "id": "ForZdKkHD1sl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function의 동작에 익숙해지는 데 시간이 걸릴 수 있습니다. 빠르게 시작하려면, 처음 사용자는 @tf.function 데코레이터로 `eager`에서 `graph` 실행으로 전환하는 경험을 얻어야 합니다.\n",
        "\n",
        "`tf.function`으로 설계하는 것은 그래프 호환 TensorFlow 프로그램을 작성하는 가장 좋은 방법일 수 있습니다. 다음은 몇 가지 팁입니다.\n",
        "\n",
        "* tf.config.run_functions_eagerly를 사용하여 초기에 그리고 자주 `eager` 실행과 `graph` 실행 사이를 전환하여 두 모드가 분기되는 if/when를 정확히 찾아냅니다.\n",
        "\n",
        "* Python 함수 외부에서 tf.Variables를 만들고 내부에서 수정합니다. tf.keras.layers, tf.keras.Models 및 tf.keras.optimizers와 같이 tf.Variable을 사용하는 객체도 마찬가지입니다.\n",
        "\n",
        "* tf.Variables 및 Keras 객체를 제외하고 외부 Python 변수에 의존하는 함수를 작성하지 마십시오. tf.function 가이드의 Python 전역 및 자유 변수에 관한 부분을 확인해 보세요\n",
        "\n",
        "*성능 이득을 최대화하려면 tf.function 아래에 가능한 한 많은 계산을 포함하십시오. 예를 들어 whole training step 또는 entire training loop를 데코레이터합니다"
      ],
      "metadata": {
        "id": "kS4AtWATD6De"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seeing the speed-up"
      ],
      "metadata": {
        "id": "eoXV_cTDD8-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`tf.function` usually improves the performance of your code, but the amount of speed-up depends on the kind of computation you run. Small computations can be dominated by the overhead of calling a graph. You can measure the difference in performance like so:"
      ],
      "metadata": {
        "id": "BywXBSNID-Uv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tf.function은 일반적으로 코드의 성능을 향상시키지만 속도 향상의 정도는 실행하고자하는 계산의 종류에 따라 다릅니다. 작은 계산은 그래프 호출의 오버헤드에 의해 좌우될 수 있습니다. 다음과 같이 성능 차이를 측정할 수 있습니다."
      ],
      "metadata": {
        "id": "mFSN0G06D_jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.random.uniform(shape=[10, 10], minval=-1, maxval=2, dtype=tf.dtypes.int32)\n",
        "\n",
        "def power(x, y):\n",
        "  result = tf.eye(10, dtype=tf.dtypes.int32)\n",
        "  for _ in range(y):\n",
        "    result = tf.matmul(x, result)\n",
        "  return result"
      ],
      "metadata": {
        "id": "UeNCyKCOEAlY"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Eager execution:\", timeit.timeit(lambda: power(x, 100), number=1000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyESeVdxECC5",
        "outputId": "512a5f9b-7154-4a5f-f44e-d4586b290400"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eager execution: 4.984682096999961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "power_as_graph = tf.function(power)\n",
        "print(\"Graph execution:\", timeit.timeit(lambda: power_as_graph(x, 100), number=1000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGmJwch3EE3C",
        "outputId": "49327a00-9af6-4694-f775-fd38af1c2a9b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph execution: 1.0169207340001094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`tf.function` is commonly used to speed up training loops, and you can learn more about it in the _Speeding-up your training step with `tf.function`_ section of the [Writing a training loop from scratch](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch) with Keras guide.\n",
        "\n",
        "Note: You can also try `tf.function(jit_compile=True)` for a more significant performance boost, especially if your code is heavy on TensorFlow control flow and uses many small tensors. Learn more in the _Explicit compilation with `tf.function(jit_compile=True)`_ section of the [XLA overview](https://www.tensorflow.org/xla)."
      ],
      "metadata": {
        "id": "gWpNypUIEIxA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performance and trade-offs\n",
        "\n",
        "Graphs can speed up your code, but the process of creating them has some overhead. For some functions, the creation of the graph takes more time than the execution of the graph. **This investment is usually quickly paid back with the performance boost of subsequent executions, but it's important to be aware that the first few  steps of any large model training can be slower due to tracing.**\n",
        "\n",
        "No matter how large your model, you want to avoid tracing frequently. The [`tf.function` guide](./function.ipynb) discusses how to set input specifications and use tensor arguments to avoid retracing in the _Controlling retracing_ section. If you find you are getting unusually poor performance, it's a good idea to check if you are retracing accidentally."
      ],
      "metadata": {
        "id": "qS4NUknIEKbB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## When is a `Function` tracing?\n",
        "\n",
        "To figure out when your `Function` is tracing, add a `print` statement to its code. As a rule of thumb, `Function` will execute the `print` statement every time it traces."
      ],
      "metadata": {
        "id": "J7PIHOXhEMFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def a_function_with_python_side_effect(x):\n",
        "  print(\"Tracing!\") # An eager-only side effect.\n",
        "  return x * x + tf.constant(2)\n",
        "\n",
        "# This is traced the first time.\n",
        "print(a_function_with_python_side_effect(tf.constant(2))) ## argument TENSOR\n",
        "# The second time through, you won't see the side effect.\n",
        "print(a_function_with_python_side_effect(tf.constant(3)))  ## argument TENSOR\n",
        "\n",
        "# print(a_function_with_python_side_effect(2))\n",
        "# print(a_function_with_python_side_effect(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7Q59CxdENHB",
        "outputId": "4b6ccae2-0be8-42d3-ba61-fca9f624dc06"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tracing!\n",
            "tf.Tensor(6, shape=(), dtype=int32)\n",
            "tf.Tensor(11, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This retraces each time the Python argument changes,\n",
        "# as a Python argument could be an epoch count or other\n",
        "# hyperparameter.\n",
        "print(a_function_with_python_side_effect(2))  ## argument : Python dtype[int]\n",
        "print(a_function_with_python_side_effect(3))  ## argument : Python dtype[int]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYOQrJ_MEPEj",
        "outputId": "1821e1fc-bd87-4d75-b1bd-6c578a222ce2"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tracing!\n",
            "tf.Tensor(6, shape=(), dtype=int32)\n",
            "Tracing!\n",
            "tf.Tensor(11, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "New Python arguments always trigger the creation of a new graph, hence the extra tracing.\n"
      ],
      "metadata": {
        "id": "Rd2m6xbLER1q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Next steps\n",
        "\n",
        "You can learn more about `tf.function` on the API reference page and by following the [Better performance with `tf.function`](./function.ipynb) guide."
      ],
      "metadata": {
        "id": "ctA1PKLBETpQ"
      }
    }
  ]
}